# Troubleshooting Guide

## Additional Links

[Kubernetes troubleshooting](https://kubernetes.io/docs/setup/independent/troubleshooting-kubeadm/)

## Installation

### Service Principal

When you first launch Epiphany on Azure you will be prompted to register your device. This process generates a token that is used to create an Azure Service Principal. At times, Azure can not fully propagate fast enough so you may see an error that resembles something like below:

```text
====> Login using service principal...
Get Token request returned http error: 400 and server response: {"error":"unauthorized_client","error_description":"AADSTS70001: Application with identifier '1c38cb1b-7cbe-4bf5-8d17-bee51d5d6502' was not found in the directory 372ee9e0-9ce0-4033-a64a-c07073a91ecd
Trace ID: fe4358f1-7250-4ad9-b6ce-c7da80101700
Correlation ID: 441a5caf-66d8-4252-a783-c0abcf60c40e
Timestamp: 2018-07-18 08:30:12Z","error_codes":[70001],"timestamp":"2018-07-18 08:30:12Z","trace_id":"fe4358f1-7250-4ad9-b6ce-c7da80101700","correlation_id":"441a5caf-66d8-4252-a783-c0abcf60c40e"}
```

Simply re-launch the command line and the Service Principal should be propagated. Repeat if necessary. This is not very common but has been seen.

### Kubernetes

Sometimes Google has a connection issue with pulling down images. You may see something like below:

```text
TASK [master : kubeadm config images pull] **********************************************************************************************
fatal: [vm-epiphany-rhel-playground-master-001]: FAILED! => {"changed": true, "cmd": "kubeadm config images pull", "delta": "0:00:01.428562", "end": "2018-07-18 08:56:47.608629", "msg": "non-zero return code", "rc": 1, "start": "2018-07-18 08:56:46.180067", "stderr": "failed to pull image \"k8s.gcr.io/kube-apiserver-amd64:v1.11.1\": exit status 1", "stderr_lines": ["failed to pull image \"k8s.gcr.io/kube-apiserver-amd64:v1.11.1\": exit status 1"], "stdout": "", "stdout_lines": []}
```

Wait a little while and try again and it will usually resolve itself quickly. If it does not go away then it could be the version of Kubernetes. For example, in the error above, v1.11.1 did not have proper images in the google registry. Changing to v1.11.0 fixed it until Google fixed their issue.

## Kafka

When running the Ansible automation there is a verification script called `kafka_producer_consumer.py` which creates a topic, produces messages and consumes messages. If the script fails for whatever reason then Ansible verification will report it as an error. An example of an issue is as follows:

```text
ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 1 larger than available brokers: 0.
```

This issue is saying the a replication of 1 is being attempted but there are no brokers '0'. This means that the kafka broker(s) are not running any longer. Kafka will start and attempt to establish connections etc. and if unable it will shutdown and log the message. So, when the verification script runs it will not be able to find a local broker (runs on each broker).

Take a look at syslog/dmesg and run `sudo systemctl status kafka`. Most likely it is related to security (TLS/SSL) and/or network but it can also be incorrect settings in the config file `/opt/kafka/config/server.properties`. Correct and rerun the automation.

## Terraform

The Terraform backend feature along with Azure Service Principal is the default configuration. This allows for multiple team members to modify the IaaS (VM) services on Azure. This works as expected from most networks. However, we have seen an error generated by Terraform on certain networks. This can be resolved simply by setting two options in the `data.yaml` file for your given environment. These are as follows:

```yaml
# Comments excluded here for clarity
terraform:
    service_principal:
        enable: false
    backend:
        enable: false
```
