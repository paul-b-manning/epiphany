---
##########################################################
# Data file for Epiphany build
# Azure specific
##########################################################

###########################
title: Epiphany Single Machine Infrastructure...

kind: datafile
version: 0.2.0

# NOTE: Any data values that are empty put "" or the value None will be used in the templates for those attributes.

core:
  # This will apply to a VPN like environment or an air-gapped like environment
  bastian:
    enable: false
    # This host will be set ONLY for environments where a bastian host is supplied to us and NOT part of the cluster build
    host: ''
    # If the bastian host has a different key
    key_path: ''
    user: ''
    # if key_path is ''
    pwd: ''

  build:
    # IMPORTANT - will be appended to release name and output folder and part of the template names
    version: &version 1.0.0
    # Type of build environment
    environment: &env development
    # Name of the given release. Version will be appended
    release: &release epiphany-single-machine
    # If repo_root is true then add that as a prefix for the output
    repo_root: true
    platform: azure
    output: '/build/$PLATFORM/infrastructure/epiphany'

  tags: &tags
    - key: environment
      value: *env
    - key: version
      value: *version
    - key: release
      value: *release
    - key: resourceType
      value: epiphany-single-machine-build
    - key: location
      value: westeurope

  # domain is used to create DNS entries or just add FQDN to hosts.yaml file used in automation
  domain:
    enable: false
    # name is the domain name itself such as epiphanyplatform.io. This value will be appended to the host name for FQDN
    name: example.com
    create_dns: false

  # These will become the role/classification you will use with the automation to group nodes for given tasks
  roles:
    - master
    - worker
    - kafka
    - zookeeper
    - prometheus
    - grafana
    - node_exporter
    - haproxy_tls_termination
    - haproxy_exporter
    - elasticsearch
    - elasticsearch-curator
    - kibana
    - filebeat
    - jmx-exporter
    - kafka-exporter
    - postgresql
    - rabbitmq
    - deployments
    # !Caution!
    # Disable this role if you don't want restart your servers
    - reboot
    # These last two must always be present
    - linux
    # - windows

  admin_user:
    name: &admin_username operations
    # May want to change to 'key' and create 'key_path' with 'pwd' or 'home'
    key_path: ~/.ssh/epiphany-operations/id_rsa

  azure:
    tags:
      <<: *tags

    terraform:
      # This version info is what version is being used at the moment. The version of Terraform in the manifest.yaml in the
      # root of the repo is for the initial install and the minum version
      version: 1.6
      service_principal:
        # Three files are required for SPs to work, az_ad_sp.json, env.sh and security.yaml. By default, these are created if the
        # 'create' attribute is true. If false then you will need to supply those two files. This allows you to create
        # a service_principal of your own instead of having one generated.
        # You will also need to override env.sh that contains the 'ARM_...' environment variables required.
        enable: true
        create: true # If you want to use an existing one then set this to false
      auth: pwd # Valid is 'pwd' and 'cert'. At this time Terraform only support 'pwd' for service principals (sp true)
      # NOTE: Backend is a Terraform resource that stores the *.tfstate files used by Terraform to store state. The default
      # is to store the state file locally but this can cause issues if working in a team environment.
      backend:
        # Only used by Terraform
        # The backend storage account is '<resource_group_name>''backend' (combined name with suffix)
        # The storage container is generated as '<resource_group_name>'-'terraform'
        # NOTE: Known issue with backend tf when having different VM types below when enabled! So, only one VM entry with count set should be used. Set to false for now...
        enable: false
        storage_account:
        storage_container:
        # sleep: 15 # Number of seconds to sleep so that Azure can create the required containers before moving on
        type: blob
        tags: *tags

    # NOTE: May want to create region/AZ sub-folders to support creating a cluster in different regions and AZ for HA...
    resource_group: &resource_group
      name: &name epiphany-single
      location: &location West Europe

    # Subscription name 
    subscription: PGGA-Epiphany-Dev

    # Azure Active Directory
    ad:
      name: *name
      role: Contributor

    standard:
      # One resource group is supported
      resource_group:
        <<: *resource_group
        # exists: false - TO BE REMOVED
        prevent_destory: true
        # IMPORTANT - Do not set lock if you plan on editing anything in the resource group! Leave it set to false until you are ready
        # ReadOnly or CanNotDelete are the only two level options if enabled!
        lock:
          # NOTE: This will cause locks.tf.wait to be generated. You will need a script to rename this to locks.tf and run apply again
          enable: true
          name: epiphany-lock
          level: ReadOnly
          notes: This locks the entire resource group!
        tags: *tags

      # This aids in boot diagnostics if there are issues:
      # https://docs.microsoft.com/en-us/azure/virtual-machines/linux/boot-diagnostics
      debug:
        # WIP
        enable: false
        storage_account:
          name: epiapps
          account:
            tier: Standard
            replication_type: LRS
            # Storage, StorageV2 and BlobStorage are supported types
            kind: StorageV2
        storage_container:
          name: debug

      availability:
        availability_set:
          enable: true
          name: ha-epiphany
          platform_fault_domain_count: 3
          platform_update_domain_count: 5
          managed: true # Best to keep this 'true' in most cases. Mixing availability set managed with vm disk unmanaged is not allowed
          tags: *tags

      security:
        ssh: &ssh
          key:
            # Public portion of the key
            file: ~/.ssh/epiphany-operations/id_rsa.pub
            data:

        vpn:
          # Make SURE all of the data is correct below before enabling 'vpn'. It can also take 30 minutes to an hour to create.
          enable: false
          name: vpn-epi-bld-apps
          # Only support RouteBased type of connection currently
          type: RouteBased
          active_active: false
          # There are two types of 'sku' (Basic and Standard). Always use Standard so any client can use.
          sku: Standard
          # Address space that is required by Virtual Network Gateway. This address space must be inside of virtual_network.address_space and do not overlap with other subnets defined  
          gateway_subnet_space: 10.1.2.0/24
          client_configuration:
          # This section is very important!
          # You must specify the address_space that will be allocated to use on the VPN side of the conection that will
          # be able to talk to your cluster.
            address_space:
              - 172.16.1.0/24
            root_certificate:
              # name is the name of the cert that was created for you by a trusted party OR a name you give a self-signed cert
              name: EpiphanyRootCa
              revoked_certificate:
                name: SomeRevokedCert
                thumbprint: bd0ef7d2c9XDFDFDFE9752169894d2
              # public_cert_data is the actual base64 public key from your cert. Put it in 'as is'. The '|' tells yaml to use 'as is'.
              public_cert_data: |
                YOUR-BASE64-CLIENT-AUTH-PUBLIC-KEY

          ip_configuration:
            name: vpn-ip-config
            public_ip:
              output:
                enable: true
                sensitive: false
              name: pip-vpn-epiphany
              address_allocation: Dynamic
              idle_timeout_in_minutes: 30

              tags: *tags

            # subnet_id is generated so use terraform variable
            private_ip:
              output:
                enable: true
                sensitive: false
              address_allocation: Dynamic
              # address only applies if 'address_allocation' is 'static'
              address: 10.0.2.5

        network_security_group:
          enable: true
          # Note: Could create an array of NSGs and reference them name + '_' + # (i.e., epiphany_nsg_001) maybe at somepoint if needed
          name: security-nsg-epiphany
          tags: *tags

          rules:            
            - name: ssh
              description: Allow SSH
              priority: 102
              direction: Inbound
              access: Allow
              protocol: Tcp
              source_port_range: "*"
              destination_port_range: "22"
              source_address_prefix: "*"
              destination_address_prefix: "*"

        virtual_network:
          name: epiphany-single-vnet
          address_space:
            - 10.1.0.0/22

        subnet:
          name: apps-subnet
          address_prefix: 10.1.1.0/24
          # Service endpoints bypass normal public route to Azure SQL, Storage and CosmosDB services
          service_endpoints:
            - Microsoft.Storage
            - Microsoft.Sql
            - Microsoft.AzureCosmosDB

      # NOTE: Managed vs Unmanaged storage
      # If you want managed storage then by default, 'storage_account' and 'storage_container' options are not required BUT
      # they are still enabled in the 'main.tf.j2' template. This could be set with an enable option.

      storage_managed_disk:
        # WIP
        enable: false
        name: epiphany-mdisk
        storage_account_type: Premium_LRS
        create_option: Empty
        disk_size_gb: 500
        count: 1

      # Once storage account is supported
      # Should use (maybe) a different storage account for different locations. Meaning, if you have two clusters (one in east and one in west) then having a storage account for east and one for west would be good since you want storage near compute.
      # No `-` in storage account name

      # 3-24 Alphanumeric only lower case
      storage_account:
        enable: true
        name: episingle
        account:
          tier: Standard
          replication_type: LRS
          # Storage, StorageV2 and BlobStorage are supported types
          kind: StorageV2

        tags: *tags

      storage_container:
        enable: false
        # 3-63 Alphanumeric lower case plus '-'
        name: epiphany-osdisks
        access_type: private

      storage_blob:
        enable: false
        name: epiphany-osdisks
        type: page
        # size in bytes in 512 increments
        size: 5120
        count: 2

      storage_image_reference: &storage_image_reference
        publisher: Canonical
        offer: UbuntuServer
        sku: 18.04-LTS
        # Never put latest on anything! Need to always pin the version number but testing we can get away with it
        version: "18.04.201810030"

        #publisher: RedHat
        #offer: RHEL
        #sku: 7-RAW
        # Never put latest on anything! Need to always pin the version number but testing we can get away with it
        #version: "7.6.2018103108"

      storage_os_disk: &storage_os_disk
        managed: true
        caching: ReadWrite
        create_option: FromImage
        disk_size_gb: 100
        managed_disk_type: Premium_LRS

      storage_data_disk: &storage_data_disk
        # Determines if a data disk will be added. If also using managed disks then use 'Attach' for create_option instead of 'Empty'
        enable: false
        count: 2
        managed: false
        caching: ReadWrite
        create_option: Empty
        disk_size_gb: 30
        managed_disk_type: Standard_LRS # Can only be Standard_LRS if using non-managed availability_set

      os_profile: &os_profile
        admin_username: operations
        admin_password: your-secret-password

      os_profile_linux_config: &os_profile_linux_config
        # NOTE: Must set to true except in early stage development! This will enforce ssh key authentication for now...
        disable_password_authentication: true

      os_profile_windows_config: &os_profile_windows_config
        # NOTE: Must set to true except in early stage development! This will enforce ssh key authentication for now...
        disable_password_authentication: true

      # Testing sets flags that allow builds to inject commands into VMs and other related items
      testing:
        enable: false

      # NOTE: This MUST equal the total number of 'count' metadata from each 'vm' array entry below
      vm_count: 1

      # VM names - 1-15 characters for Windows and 1-64 characters for Linux
      vms:
        - name: vm-master  
          size: Standard_DS4_v2
          os_type: linux
          count: 1
          # One host will need to be a bastian host UNLESS the bastian host is provided in another way
          bastian_host: false
          # roles are how you define a grouping of nodes. These values will be used to create an inventory of your cluster
          # Must be a member of the 'role' in core
          roles:
          - linux
          - master
          - node_exporter
          - prometheus
          - grafana
          - rabbitmq
          - postgresql
          - deployments
          - reboot

          delete_os_disk_on_termination: false
          delete_data_disks_on_termination: false
          # NOTE: This must match the interfaces public_ip options. If one interface has enabled public_ip then this MUST be true else false
          public_ips: true
          depends_on:
            # Put the name of the resource. If a VM then only put the 'name:' value. The count portion will be automatically added
            - '${var.master_depends_on}'
          tags: *tags

          security:
            # Each node will have firewalld (redhat) enabled and allowing only given ports, remember that Epiphany needs port 22 for bootstrapping environments
            firewall:
              enable: false
              ports_open:
                - 22/tcp
                - 443/tcp

          # NOTE: For Kubernetes builds we should *not* use provisioners to bootstrap any data. The point is to build a common
          # infrastructure and then collect IPs etc. that are required for K8s automation to build. The ONLY possible
          # exception is for automated testing in VSTS 
          bootstrap:
            # Can use the global values or override them on a per vm type basis
            ssh: *ssh

            provisioners:
              file:
                enable: false
                # NOTE: Pay close attention to the trailing '/' for 'source'. If you leave '/' off of the end of source then the directory tree will be copied to 'destination'. If you add '/' then the contents of that directory will be copied into the destination directory.
                source: "../../../../core/src/scripts/kubernetes/linux"
                destination: "/home/${var.admin_username}"

              remote_exec:
                enable: false
                # NOTE: Use Terraform vars if you need to embed variables in the commands.
                inline: # Example is below and only here to show
                  - 'chmod +x ${var.file_destination}/linux/make-executable.sh'
                  - '${var.file_destination}/linux/make-executable.sh'
                  - 'echo ${var.admin_password} | sudo -S ${var.file_destination}/linux/prepare-system-kubernetes-redhat.sh'

                testing_inline:
                  - 'echo \"##vso[task.setvariable variable=toPrint]Print Me Please\"'

          interfaces:
            # A VM can have multiple IP addresses and interfaces. In this case we are
            # saying there is one public IP per network interface
            - network_interface:
                # name has vm name appended to it so only put basic type name here
                name: nic
                primary: true
                tags: *tags

                # This only works with certain size VMs
                # Accelerated Networking is supported on most general purpose and compute-optimized instance sizes with 2 or more vCPUs.
                # These supported series are: D/DSv2 and F/Fs. On instances that support hyperthreading, Accelerated Networking is supported
                # on VM instances with 4 or more vCPUs. Supported series are: D/DSv3, E/ESv3, Fsv2, and Ms/Mms.
                # https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli
                enable_accelerated_networking: false

                ip_configuration:
                  name: ip-config
                  # subnet_id is generated so use terraform variable
                  private_ip:
                    output:
                      enable: true
                      sensitive: false
                    address_allocation: Dynamic
                    # address only applies if 'address_allocation' is 'static'
                    address: 10.0.2.5

                public_ip:
                  # If you set to false there must be some host set as a bastian host
                  enable: true
                  output:
                    enable: true
                    sensitive: false
                  name: pip-epiphany
                  address_allocation: static
                  idle_timeout_in_minutes: 30
                  sku: Standard

                  tags: *tags

  kubernetes:
    version: 1.13.0
    # image_registry_secrets:
    # - name: regcred
    #   server_url: your-registry-url 
    #   username: your-registry-username
    #   password: your-registry-password
    #   email: your-registry-email
    #   namespace: your-secret-namespace
    storage:
      enable: true
      #valid chocies:
        #azure-file
        #WIP
      type: azure-file
      tags: *tags
      quota: 50
    deployments:
#      - name: rabbitmq 
#        image_path: rabbitmq:3.7.10
#        # image_pull_secret_name: regcred # optional
#        service:
#          name: rabbitmq-cluster
#          port: 30672
#          management_port: 31672
#          replicas: 5
#          namespace: queue
#        rabbitmq:
#          # amqp_port: 5672 #optional - default 5672  
#          plugins: # optional list of RabbitMQ plugins
#            - rabbitmq_management
#            - rabbitmq_management_agent
#          policies: # optional list of RabbitMQ policies
#            - name: ha-policy2
#              pattern: ".*"
#              definitions:
#                ha-mode: all
#          custom_configurations: #optional list of RabbitMQ configurations (new format -> https://www.rabbitmq.com/configure.html)
#            - name: vm_memory_high_watermark.relative
#              value: 0.5
#          cluster:
#            # is_clustered: true #redundant in in-Kubernetes installation, it will always be clustered
#            # cookie: "cookieSetFromDataYaml" #optional - default value will be random generated string
      - name: auth-service # this service require postgresql to be installed in cluster
        image_path: jboss/keycloak:4.8.3.Final
        # image_pull_secret_name: regcred
        service:
          name: auth-service
          port: 30104
          replicas: 2
          namespace: auth-tools
          admin_user: admin
          admin_password: admin
        database: 
          name: "authDb"    
          # port: "5432" # leave it when default
          user: "authDbadmin"
          password: "authDbpwd"

#  haproxy:
#    stats:
#      enable: true
#      user: operations
#      password: your-haproxy-stats-pwd
#    frontend:
#      - name: https_front
#        port: 443
#        https: yes
#        backend:
#        - http_back1
#    backend:
#      - name: http_back1
#        server_groups:
#        - worker
#        #servers:
#        # Definition for server to that hosts the application.
#        #- name: "node1"
#        #  address: "epiphany-vm1.domain.com"
#        port: 30104

  monitoring:
    alerts:
      enable: True # required value
      handlers:
        mail:
          enable: False # required value
          smtp_from: "alert@test.com"
          smtp_host: "smtp-url:smtp-port"
          smtp_auth_username: "your-smtp-user@domain.com"
          smtp_auth_password: "your-smtp-password"
          smtp_require_tls: True
          recipients: 
          - recipient1@domain.com
          - recipient2@domain.com
        slack:
          enable: False # required value
          api_url: url-to-slack-workspace-api.slack.com
        pagerduty:
          enable: False # required value
          service_key: your-service-key 
      rules:
      - name: "UpDown"
        expression: up == 0
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Node is down." 
      - name: "DiskSpace"
        expression: ((node_filesystem_avail_bytes* 100) / node_filesystem_size_bytes) < 20 # 100 - 80
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Disk usage is above 80%" 
      - name: "DiskSpacePrediction"
        expression: predict_linear(node_filesystem_free_bytes{job="node"}[1h], 48 * 3600) < 0
        duration: 1m #1s, 1m, 1h, 1d, 1w, ...
        severity: warning
        message: "Disk will run out of space in less than 48h" 
      - name: "MemoryUsage"
        expression: (sum by (instance) (node_memory_MemTotal_bytes) - sum by (instance)(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) ) / sum by (instance)(node_memory_MemTotal_bytes) * 100 > 80
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: warning
        message: "Server memory has been used in more than 80% during last 15 minutes." 
      - name: "CpuLoad"
        expression: 100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100) > 80
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "CPU utilization has exceeded 80% over last 15 minutes." 
      - name: "KafkaConsumerLag"
        expression: sum by(consumergroup) (kafka_consumergroup_lag) > 1000
        duration: 15m #1s, 1m, 1h, 1d, 1w, ...
        severity: critical
        message: "Kafka consumers are lagging more than 1000 messages over last 15 minutes." 

rabbitmq:
  amqp_port: 5672 #optional - default 5672  
  plugins: # optional list of RabbitMQ plugins
    - rabbitmq_management
    - rabbitmq_management_agent
  policies: # optional list of RabbitMQ policies
    - name: ha-policy2
      pattern: ".*"
      definitions:
        ha-mode: all
#  custom_configurations: #optional list of RabbitMQ configurations (new format -> https://www.rabbitmq.com/configure.html)
#    - name: vm_memory_high_watermark.relative
#      value: 0.6
  cluster:
    is_clustered: false #optional - default false
    cookie: "cookieSetFromDataYaml" #optional - default value will be random generated string 